{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86cc17b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/kaixin/COVID_Mobility/Data/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "  File \"/tmp/ipykernel_195931/1015942712.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "ModuleNotFoundError: No module named 'pandas'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kaixin/COVID_Mobility/Data/.venv/lib/python3.8/site-packages/pygments/styles/__init__.py\", line 90, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kaixin/COVID_Mobility/Data/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "  File \"/home/kaixin/COVID_Mobility/Data/.venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "  File \"/home/kaixin/COVID_Mobility/Data/.venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "  File \"/home/kaixin/COVID_Mobility/Data/.venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "  File \"/home/kaixin/COVID_Mobility/Data/.venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1030, in format_exception_as_a_whole\n",
      "  File \"/home/kaixin/COVID_Mobility/Data/.venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1081, in get_records\n",
      "  File \"/home/kaixin/COVID_Mobility/Data/.venv/lib/python3.8/site-packages/pygments/styles/__init__.py\", line 92, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "# import urllib\n",
    "# import ast\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# import datetime\n",
    "# from calendar import monthrange\n",
    "\n",
    "# code_data = pd.read_csv(\"code_data.csv\") #data associating cities and regions names to their respective numeric codes\n",
    "\n",
    "# month = datetime.datetime.now().month #take current month\n",
    "# year = datetime.datetime.now().year #take current year\n",
    "# numdays = monthrange(year, month)[1] #number of days in current month\n",
    "# dates_sep = [str(datetime.date(year, month, day)) for day in range(1, numdays+1)] #dates as hyphen separated strings for naming\n",
    "# dates = [date.replace(\"-\", \"\") for date in dates_sep] #dates as solid strings for algorithm readability\n",
    "\n",
    "# code_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86ee58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]\n",
      "  0%|                                                                                          | 0/369 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                                                                                 | 1/369 [00:01<06:13,  1.02s/it]\u001b[A\n",
      "  1%|▍                                                                                 | 2/369 [00:02<06:17,  1.03s/it]\u001b[A\n",
      "  1%|▋                                                                                 | 3/369 [00:02<06:01,  1.01it/s]\u001b[A\n",
      "  1%|▉                                                                                 | 4/369 [00:03<06:02,  1.01it/s]\u001b[A\n",
      "  1%|█                                                                                 | 5/369 [00:05<07:25,  1.22s/it]\u001b[A\n",
      "  2%|█▎                                                                                | 6/369 [00:06<06:57,  1.15s/it]\u001b[A\n",
      "  2%|█▌                                                                                | 7/369 [00:07<06:35,  1.09s/it]\u001b[A\n",
      "  2%|█▊                                                                                | 8/369 [00:08<06:18,  1.05s/it]\u001b[A\n",
      "  2%|██                                                                                | 9/369 [00:09<06:02,  1.01s/it]\u001b[A\n",
      "  3%|██▏                                                                              | 10/369 [00:11<07:11,  1.20s/it]\u001b[A\n",
      "  3%|██▍                                                                              | 11/369 [00:12<06:40,  1.12s/it]\u001b[A\n",
      "  3%|██▋                                                                              | 12/369 [00:12<06:19,  1.06s/it]\u001b[A\n",
      "  4%|██▊                                                                              | 13/369 [00:13<06:03,  1.02s/it]\u001b[A\n",
      "  4%|███                                                                              | 14/369 [00:14<06:01,  1.02s/it]\u001b[A\n",
      "  4%|███▎                                                                             | 15/369 [00:15<05:51,  1.01it/s]\u001b[A\n",
      "  4%|███▌                                                                             | 16/369 [00:16<05:46,  1.02it/s]\u001b[A\n",
      "  5%|███▋                                                                             | 17/369 [00:18<06:08,  1.05s/it]\u001b[A\n",
      "  5%|███▉                                                                             | 18/369 [00:18<05:55,  1.01s/it]\u001b[A\n",
      "  5%|████▏                                                                            | 19/369 [00:19<05:57,  1.02s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "### Extract move-in data from Baidu qianxi ###\n",
    "error_code = [] #error produced by missing data\n",
    "error_date = [] #date associated to error\n",
    "errors = []\n",
    "moveins = [] #list for move-in data\n",
    "\n",
    "for d in tqdm(range(len(dates))): #loop over dates\n",
    "    date = dates[d]\n",
    "    by_cities = [] #list for data from cities at a given date\n",
    "    for i in tqdm(range(len(code_data))):\n",
    "        code = code_data.City_Code[i] #take code of city for matching\n",
    "        #qianxi website by code and date\n",
    "        url = \"http://huiyan.baidu.com/migration/cityrank.jsonp?dt=province&id=\"+str(code)+\"&type=move_in&date=\"+date\n",
    "        #try runing code or except if error (add to error lists)\n",
    "        try:\n",
    "            file = urllib.request.urlopen(url, timeout=20) #increase timeout to avoid connection error\n",
    "            file = file.read() \n",
    "            dict_str = file.decode(\"UTF-8\") #decore file from URL as UTF-8 chracter map\n",
    "            dict_str = dict_str.replace('\\ncb({\"errno\":0,\"errmsg\":\"SUCCESS\",\"data\":{\"list\":[{', \"{\") #transform to string\n",
    "            dict_str = dict_str.replace(\"]}})\", \"\") #remove irrelevant characters\n",
    "            data = ast.literal_eval(dict_str) #turn string into data\n",
    "            data = pd.DataFrame(list(data)) #create dataframe\n",
    "            # add column names and data to dataframe by matching city codes\n",
    "            data.columns = [\"City_CH\", \"Prov_CH\", \"proportion\"]\n",
    "            data[\"City_EN_origin\"] = [code_data[code_data.City_CH==c].City_EN.values[0] for c in data.City_CH]\n",
    "            data[\"Prov_EN_origin\"] = [code_data[code_data.City_CH==c].Prov_EN.values[0] for c in data.City_CH]\n",
    "            data[\"City_EN_destination\"] = np.repeat(code_data[code_data.City_Code==code].City_EN.values[0], len(data))\n",
    "            data[\"Prov_EN_destination\"] = np.repeat(code_data[code_data.City_Code==code].Prov_EN.values[0], len(data))\n",
    "            data[\"City_CH_origin\"] = [code_data[code_data.City_CH==c].City_CH.values[0] for c in data.City_CH]\n",
    "            data[\"Prov_CH_origin\"] = [code_data[code_data.City_CH==c].Prov_CH.values[0] for c in data.City_CH]\n",
    "            data[\"City_CH_destination\"] = data.City_CH.values\n",
    "            data[\"Prov_CH_destination\"] = data.Prov_CH.values\n",
    "            data[\"City_code_origin\"] = [code_data[code_data.City_CH==c].City_Code.values[0] for c in data.City_CH]\n",
    "            data[\"Prov_code_origin\"] = [code_data[code_data.City_CH==c].Prov_Code.values[0] for c in data.City_CH]\n",
    "            data[\"City_code_destination\"] = np.repeat(code_data[code_data.City_Code==code].City_Code.values[0], len(data))\n",
    "            data[\"Prov_code_destination\"] = np.repeat(code_data[code_data.City_Code==code].Prov_Code.values[0], len(data))\n",
    "            by_cities.append(data)\n",
    "        except:\n",
    "            error_code.append(code)\n",
    "            error_date.append(dates_sep[d])\n",
    "            continue\n",
    "    errors.append(pd.DataFrame({\"error_code\":error_code, \"error_date\":error_date})) #errors list\n",
    "    data = pd.concat(by_cities) #data by city at a given date\n",
    "    data['date'] = dates_sep[d] #add dates to dataframe\n",
    "    moveins.append(data) #data list\n",
    "#errors = = pd.concat(errors)\n",
    "#errors.to_csv(\"missing_movein.csv\") #save errors dataframe (optional)\n",
    "data = pd.concat(moveins)\n",
    "data.to_csv(\"baidu_qianxi_data_movein\"+year+month+\".csv\", index=False, encoding='utf_8_sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]\n",
      "  0%|                                                                                          | 0/369 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                                                                                 | 1/369 [00:01<06:23,  1.04s/it]\u001b[A\n",
      "  1%|▍                                                                                 | 2/369 [00:02<06:17,  1.03s/it]\u001b[A\n",
      "  1%|▋                                                                                 | 3/369 [00:03<06:01,  1.01it/s]\u001b[A\n",
      "  1%|▉                                                                                 | 4/369 [00:03<05:55,  1.03it/s]\u001b[A\n",
      "  1%|█                                                                                 | 5/369 [00:04<05:52,  1.03it/s]\u001b[A\n",
      "  2%|█▎                                                                                | 6/369 [00:05<05:59,  1.01it/s]\u001b[A\n",
      "  2%|█▌                                                                                | 7/369 [00:07<06:08,  1.02s/it]\u001b[A\n",
      "  2%|█▊                                                                                | 8/369 [00:08<06:14,  1.04s/it]\u001b[A\n",
      "  2%|██                                                                                | 9/369 [00:09<06:03,  1.01s/it]\u001b[A\n",
      "  3%|██▏                                                                              | 10/369 [00:10<05:56,  1.01it/s]\u001b[A\n",
      "  3%|██▍                                                                              | 11/369 [00:11<05:56,  1.00it/s]\u001b[A\n",
      "  3%|██▋                                                                              | 12/369 [00:12<06:17,  1.06s/it]\u001b[A\n",
      "  4%|██▊                                                                              | 13/369 [00:13<06:00,  1.01s/it]\u001b[A\n",
      "  4%|███                                                                              | 14/369 [00:14<05:52,  1.01it/s]\u001b[A\n",
      "  4%|███▎                                                                             | 15/369 [00:15<06:08,  1.04s/it]\u001b[A\n",
      "  4%|███▌                                                                             | 16/369 [00:16<06:01,  1.02s/it]\u001b[A\n",
      "  5%|███▋                                                                             | 17/369 [00:17<05:56,  1.01s/it]\u001b[A\n",
      "  5%|███▉                                                                             | 18/369 [00:18<05:49,  1.00it/s]\u001b[A\n",
      "  5%|████▏                                                                            | 19/369 [00:19<06:04,  1.04s/it]\u001b[A\n",
      "  5%|████▍                                                                            | 20/369 [00:20<05:56,  1.02s/it]\u001b[A\n",
      "  6%|████▌                                                                            | 21/369 [00:21<05:51,  1.01s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "### Extract move-out data from Baidu qianxi ###\n",
    "# operation is same as for move-in data above\n",
    "error_code = []\n",
    "error_date = []\n",
    "errors = []\n",
    "moveouts = []\n",
    "for d in tqdm(range(len(dates))):  \n",
    "    date = dates[d]\n",
    "    by_cities = []\n",
    "    for i in tqdm(range(len(code_data))):\n",
    "        code = code_data.City_Code[i]\n",
    "        url = \"http://huiyan.baidu.com/migration/cityrank.jsonp?dt=province&id=\"+str(code)+\"&type=move_out&date=\"+date\n",
    "        try:\n",
    "            file = urllib.request.urlopen(url, timeout=20) #increase timeout to avoid connection error\n",
    "            file = file.read()\n",
    "            dict_str = file.decode(\"UTF-8\")\n",
    "            dict_str = dict_str.replace('\\ncb({\"errno\":0,\"errmsg\":\"SUCCESS\",\"data\":{\"list\":[{', \"{\")\n",
    "            dict_str = dict_str.replace(\"]}})\", \"\")\n",
    "            data = ast.literal_eval(dict_str)\n",
    "            data = pd.DataFrame(list(data))\n",
    "            data.columns = [\"City_CH\", \"Prov_CH\", \"proportion\"]\n",
    "            data[\"City_EN_destination\"] = [code_data[code_data.City_CH==c].City_EN.values[0] for c in data.City_CH]\n",
    "            data[\"Prov_EN_destination\"] = [code_data[code_data.City_CH==c].Prov_EN.values[0] for c in data.City_CH]\n",
    "            data[\"City_EN_origin\"] = np.repeat(code_data[code_data.City_Code==code].City_EN.values[0], len(data))\n",
    "            data[\"Prov_EN_origin\"] = np.repeat(code_data[code_data.City_Code==code].Prov_EN.values[0], len(data))\n",
    "            data[\"City_CH_destination\"] = [code_data[code_data.City_CH==c].City_CH.values[0] for c in data.City_CH]\n",
    "            data[\"Prov_CH_destination\"] = [code_data[code_data.City_CH==c].Prov_CH.values[0] for c in data.City_CH]\n",
    "            data[\"City_CH_origin\"] = data.City_CH.values\n",
    "            data[\"Prov_CH_origin\"] = data.Prov_CH.values\n",
    "            data[\"City_code_origin\"] = [code_data[code_data.City_CH==c].City_Code.values[0] for c in data.City_CH]\n",
    "            data[\"Prov_code_origin\"] = [code_data[code_data.City_CH==c].Prov_Code.values[0] for c in data.City_CH]\n",
    "            data[\"City_code_destination\"] = np.repeat(code_data[code_data.City_Code==code].City_Code.values[0], len(data))\n",
    "            data[\"Prov_code_destination\"] = np.repeat(code_data[code_data.City_Code==code].Prov_Code.values[0], len(data))\n",
    "            by_cities.append(data)\n",
    "        except:\n",
    "            error_code.append(code)\n",
    "            error_date.append(dates_sep[d])\n",
    "            continue\n",
    "    errors.append(pd.DataFrame({\"error_code\":error_code, \"error_date\":error_date}))\n",
    "    data = pd.concat(by_cities)\n",
    "    data['date'] = dates_sep[d]\n",
    "    moveouts.append(data)\n",
    "#errors = = pd.concat(errors)\n",
    "#errors.to_csv(\"missing_moveout.csv\")\n",
    "data = pd.concat(moveouts)\n",
    "data.to_csv(\"baidu_qianxi_data_moveout\"+year+month+\".csv\", index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b503a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
