{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86cc17b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City_CH</th>\n",
       "      <th>Prov_CH</th>\n",
       "      <th>Prov_EN</th>\n",
       "      <th>City_Code</th>\n",
       "      <th>City_EN</th>\n",
       "      <th>Prov_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>北京市</td>\n",
       "      <td>北京市</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>110000</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>110000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>天津市</td>\n",
       "      <td>天津市</td>\n",
       "      <td>Tianjin</td>\n",
       "      <td>120000</td>\n",
       "      <td>Tianjin</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>石家庄市</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>130100</td>\n",
       "      <td>Shijiazhuang</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>唐山市</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>130200</td>\n",
       "      <td>Tangshan</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>秦皇岛市</td>\n",
       "      <td>河北省</td>\n",
       "      <td>Hebei</td>\n",
       "      <td>130300</td>\n",
       "      <td>Qinhuangdao</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>可克达拉市</td>\n",
       "      <td>新疆</td>\n",
       "      <td>Xinjiang</td>\n",
       "      <td>659008</td>\n",
       "      <td>Kelada</td>\n",
       "      <td>650000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>昆玉市</td>\n",
       "      <td>新疆</td>\n",
       "      <td>Xinjiang</td>\n",
       "      <td>659009</td>\n",
       "      <td>Kunyu</td>\n",
       "      <td>650000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>台湾省</td>\n",
       "      <td>台湾省</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>710000</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>710000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>香港特别行政区</td>\n",
       "      <td>特别行政区</td>\n",
       "      <td>Hongkong</td>\n",
       "      <td>810000</td>\n",
       "      <td>Hongkong</td>\n",
       "      <td>810000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>澳门特别行政区</td>\n",
       "      <td>特别行政区</td>\n",
       "      <td>Macao</td>\n",
       "      <td>820000</td>\n",
       "      <td>Macao</td>\n",
       "      <td>820000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     City_CH Prov_CH   Prov_EN  City_Code       City_EN  Prov_Code\n",
       "0        北京市     北京市   Beijing     110000       Beijing   110000.0\n",
       "1        天津市     天津市   Tianjin     120000       Tianjin   120000.0\n",
       "2       石家庄市     河北省     Hebei     130100  Shijiazhuang   130000.0\n",
       "3        唐山市     河北省     Hebei     130200      Tangshan   130000.0\n",
       "4       秦皇岛市     河北省     Hebei     130300   Qinhuangdao   130000.0\n",
       "..       ...     ...       ...        ...           ...        ...\n",
       "364    可克达拉市      新疆  Xinjiang     659008        Kelada   650000.0\n",
       "365      昆玉市      新疆  Xinjiang     659009         Kunyu   650000.0\n",
       "366      台湾省     台湾省    Taiwan     710000        Taiwan   710000.0\n",
       "367  香港特别行政区   特别行政区  Hongkong     810000      Hongkong   810000.0\n",
       "368  澳门特别行政区   特别行政区     Macao     820000         Macao   820000.0\n",
       "\n",
       "[369 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import ast\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from calendar import monthrange\n",
    "\n",
    "code_data = pd.read_csv(\"code_data.csv\") #data associating cities and regions names to their respective numeric codes\n",
    "\n",
    "month = datetime.datetime.now().month #take current month\n",
    "year = datetime.datetime.now().year #take current year\n",
    "numdays = monthrange(year, month)[1] #number of days in current month\n",
    "dates_sep = [str(datetime.date(year, month, day)) for day in range(1, numdays+1)] #dates as hyphen separated strings for naming\n",
    "dates = [date.replace(\"-\", \"\") for date in dates_sep] #dates as solid strings for algorithm readability\n",
    "\n",
    "code_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86ee58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]\n",
      "  0%|                                                                                          | 0/369 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                                                                                 | 1/369 [00:01<06:13,  1.02s/it]\u001b[A\n",
      "  1%|▍                                                                                 | 2/369 [00:02<06:17,  1.03s/it]\u001b[A\n",
      "  1%|▋                                                                                 | 3/369 [00:02<06:01,  1.01it/s]\u001b[A\n",
      "  1%|▉                                                                                 | 4/369 [00:03<06:02,  1.01it/s]\u001b[A\n",
      "  1%|█                                                                                 | 5/369 [00:05<07:25,  1.22s/it]\u001b[A\n",
      "  2%|█▎                                                                                | 6/369 [00:06<06:57,  1.15s/it]\u001b[A\n",
      "  2%|█▌                                                                                | 7/369 [00:07<06:35,  1.09s/it]\u001b[A\n",
      "  2%|█▊                                                                                | 8/369 [00:08<06:18,  1.05s/it]\u001b[A\n",
      "  2%|██                                                                                | 9/369 [00:09<06:02,  1.01s/it]\u001b[A\n",
      "  3%|██▏                                                                              | 10/369 [00:11<07:11,  1.20s/it]\u001b[A\n",
      "  3%|██▍                                                                              | 11/369 [00:12<06:40,  1.12s/it]\u001b[A\n",
      "  3%|██▋                                                                              | 12/369 [00:12<06:19,  1.06s/it]\u001b[A\n",
      "  4%|██▊                                                                              | 13/369 [00:13<06:03,  1.02s/it]\u001b[A\n",
      "  4%|███                                                                              | 14/369 [00:14<06:01,  1.02s/it]\u001b[A\n",
      "  4%|███▎                                                                             | 15/369 [00:15<05:51,  1.01it/s]\u001b[A\n",
      "  4%|███▌                                                                             | 16/369 [00:16<05:46,  1.02it/s]\u001b[A\n",
      "  5%|███▋                                                                             | 17/369 [00:18<06:08,  1.05s/it]\u001b[A\n",
      "  5%|███▉                                                                             | 18/369 [00:18<05:55,  1.01s/it]\u001b[A\n",
      "  5%|████▏                                                                            | 19/369 [00:19<05:57,  1.02s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "### Extract move-in data from Baidu qianxi ###\n",
    "error_code = [] #error produced by missing data\n",
    "error_date = [] #date associated to error\n",
    "errors = []\n",
    "moveins = [] #list for move-in data\n",
    "\n",
    "for d in tqdm(range(len(dates))): #loop over dates\n",
    "    date = dates[d]\n",
    "    by_cities = [] #list for data from cities at a given date\n",
    "    for i in tqdm(range(len(code_data))):\n",
    "        code = code_data.City_Code[i] #take code of city for matching\n",
    "        #qianxi website by code and date\n",
    "        url = \"http://huiyan.baidu.com/migration/cityrank.jsonp?dt=province&id=\"+str(code)+\"&type=move_in&date=\"+date\n",
    "        #try runing code or except if error (add to error lists)\n",
    "        try:\n",
    "            file = urllib.request.urlopen(url, timeout=20) #increase timeout to avoid connection error\n",
    "            file = file.read() \n",
    "            dict_str = file.decode(\"UTF-8\") #decore file from URL as UTF-8 chracter map\n",
    "            dict_str = dict_str.replace('\\ncb({\"errno\":0,\"errmsg\":\"SUCCESS\",\"data\":{\"list\":[{', \"{\") #transform to string\n",
    "            dict_str = dict_str.replace(\"]}})\", \"\") #remove irrelevant characters\n",
    "            data = ast.literal_eval(dict_str) #turn string into data\n",
    "            data = pd.DataFrame(list(data)) #create dataframe\n",
    "            # add column names and data to dataframe by matching city codes\n",
    "            data.columns = [\"City_CH\", \"Prov_CH\", \"proportion\"]\n",
    "            data[\"City_EN_origin\"] = [code_data[code_data.City_CH==c].City_EN.values[0] for c in data.City_CH]\n",
    "            data[\"Prov_EN_origin\"] = [code_data[code_data.City_CH==c].Prov_EN.values[0] for c in data.City_CH]\n",
    "            data[\"City_EN_destination\"] = np.repeat(code_data[code_data.City_Code==code].City_EN.values[0], len(data))\n",
    "            data[\"Prov_EN_destination\"] = np.repeat(code_data[code_data.City_Code==code].Prov_EN.values[0], len(data))\n",
    "            data[\"City_CH_origin\"] = [code_data[code_data.City_CH==c].City_CH.values[0] for c in data.City_CH]\n",
    "            data[\"Prov_CH_origin\"] = [code_data[code_data.City_CH==c].Prov_CH.values[0] for c in data.City_CH]\n",
    "            data[\"City_CH_destination\"] = data.City_CH.values\n",
    "            data[\"Prov_CH_destination\"] = data.Prov_CH.values\n",
    "            data[\"City_code_origin\"] = [code_data[code_data.City_CH==c].City_Code.values[0] for c in data.City_CH]\n",
    "            data[\"Prov_code_origin\"] = [code_data[code_data.City_CH==c].Prov_Code.values[0] for c in data.City_CH]\n",
    "            data[\"City_code_destination\"] = np.repeat(code_data[code_data.City_Code==code].City_Code.values[0], len(data))\n",
    "            data[\"Prov_code_destination\"] = np.repeat(code_data[code_data.City_Code==code].Prov_Code.values[0], len(data))\n",
    "            by_cities.append(data)\n",
    "        except:\n",
    "            error_code.append(code)\n",
    "            error_date.append(dates_sep[d])\n",
    "            continue\n",
    "    errors.append(pd.DataFrame({\"error_code\":error_code, \"error_date\":error_date})) #errors list\n",
    "    data = pd.concat(by_cities) #data by city at a given date\n",
    "    data['date'] = dates_sep[d] #add dates to dataframe\n",
    "    moveins.append(data) #data list\n",
    "#errors = = pd.concat(errors)\n",
    "#errors.to_csv(\"missing_movein.csv\") #save errors dataframe (optional)\n",
    "data = pd.concat(moveins)\n",
    "data.to_csv(\"baidu_qianxi_data_movein\"+year+month+\".csv\", index=False, encoding='utf_8_sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]\n",
      "  0%|                                                                                          | 0/369 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▏                                                                                 | 1/369 [00:01<06:23,  1.04s/it]\u001b[A\n",
      "  1%|▍                                                                                 | 2/369 [00:02<06:17,  1.03s/it]\u001b[A\n",
      "  1%|▋                                                                                 | 3/369 [00:03<06:01,  1.01it/s]\u001b[A\n",
      "  1%|▉                                                                                 | 4/369 [00:03<05:55,  1.03it/s]\u001b[A\n",
      "  1%|█                                                                                 | 5/369 [00:04<05:52,  1.03it/s]\u001b[A\n",
      "  2%|█▎                                                                                | 6/369 [00:05<05:59,  1.01it/s]\u001b[A\n",
      "  2%|█▌                                                                                | 7/369 [00:07<06:08,  1.02s/it]\u001b[A\n",
      "  2%|█▊                                                                                | 8/369 [00:08<06:14,  1.04s/it]\u001b[A\n",
      "  2%|██                                                                                | 9/369 [00:09<06:03,  1.01s/it]\u001b[A\n",
      "  3%|██▏                                                                              | 10/369 [00:10<05:56,  1.01it/s]\u001b[A\n",
      "  3%|██▍                                                                              | 11/369 [00:11<05:56,  1.00it/s]\u001b[A\n",
      "  3%|██▋                                                                              | 12/369 [00:12<06:17,  1.06s/it]\u001b[A\n",
      "  4%|██▊                                                                              | 13/369 [00:13<06:00,  1.01s/it]\u001b[A\n",
      "  4%|███                                                                              | 14/369 [00:14<05:52,  1.01it/s]\u001b[A\n",
      "  4%|███▎                                                                             | 15/369 [00:15<06:08,  1.04s/it]\u001b[A\n",
      "  4%|███▌                                                                             | 16/369 [00:16<06:01,  1.02s/it]\u001b[A\n",
      "  5%|███▋                                                                             | 17/369 [00:17<05:56,  1.01s/it]\u001b[A\n",
      "  5%|███▉                                                                             | 18/369 [00:18<05:49,  1.00it/s]\u001b[A\n",
      "  5%|████▏                                                                            | 19/369 [00:19<06:04,  1.04s/it]\u001b[A\n",
      "  5%|████▍                                                                            | 20/369 [00:20<05:56,  1.02s/it]\u001b[A\n",
      "  6%|████▌                                                                            | 21/369 [00:21<05:51,  1.01s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "### Extract move-out data from Baidu qianxi ###\n",
    "# operation is same as for move-in data above\n",
    "error_code = []\n",
    "error_date = []\n",
    "errors = []\n",
    "moveouts = []\n",
    "for d in tqdm(range(len(dates))):  \n",
    "    date = dates[d]\n",
    "    by_cities = []\n",
    "    for i in tqdm(range(len(code_data))):\n",
    "        code = code_data.City_Code[i]\n",
    "        url = \"http://huiyan.baidu.com/migration/cityrank.jsonp?dt=province&id=\"+str(code)+\"&type=move_out&date=\"+date\n",
    "        try:\n",
    "            file = urllib.request.urlopen(url, timeout=20) #increase timeout to avoid connection error\n",
    "            file = file.read()\n",
    "            dict_str = file.decode(\"UTF-8\")\n",
    "            dict_str = dict_str.replace('\\ncb({\"errno\":0,\"errmsg\":\"SUCCESS\",\"data\":{\"list\":[{', \"{\")\n",
    "            dict_str = dict_str.replace(\"]}})\", \"\")\n",
    "            data = ast.literal_eval(dict_str)\n",
    "            data = pd.DataFrame(list(data))\n",
    "            data.columns = [\"City_CH\", \"Prov_CH\", \"proportion\"]\n",
    "            data[\"City_EN_destination\"] = [code_data[code_data.City_CH==c].City_EN.values[0] for c in data.City_CH]\n",
    "            data[\"Prov_EN_destination\"] = [code_data[code_data.City_CH==c].Prov_EN.values[0] for c in data.City_CH]\n",
    "            data[\"City_EN_origin\"] = np.repeat(code_data[code_data.City_Code==code].City_EN.values[0], len(data))\n",
    "            data[\"Prov_EN_origin\"] = np.repeat(code_data[code_data.City_Code==code].Prov_EN.values[0], len(data))\n",
    "            data[\"City_CH_destination\"] = [code_data[code_data.City_CH==c].City_CH.values[0] for c in data.City_CH]\n",
    "            data[\"Prov_CH_destination\"] = [code_data[code_data.City_CH==c].Prov_CH.values[0] for c in data.City_CH]\n",
    "            data[\"City_CH_origin\"] = data.City_CH.values\n",
    "            data[\"Prov_CH_origin\"] = data.Prov_CH.values\n",
    "            data[\"City_code_origin\"] = [code_data[code_data.City_CH==c].City_Code.values[0] for c in data.City_CH]\n",
    "            data[\"Prov_code_origin\"] = [code_data[code_data.City_CH==c].Prov_Code.values[0] for c in data.City_CH]\n",
    "            data[\"City_code_destination\"] = np.repeat(code_data[code_data.City_Code==code].City_Code.values[0], len(data))\n",
    "            data[\"Prov_code_destination\"] = np.repeat(code_data[code_data.City_Code==code].Prov_Code.values[0], len(data))\n",
    "            by_cities.append(data)\n",
    "        except:\n",
    "            error_code.append(code)\n",
    "            error_date.append(dates_sep[d])\n",
    "            continue\n",
    "    errors.append(pd.DataFrame({\"error_code\":error_code, \"error_date\":error_date}))\n",
    "    data = pd.concat(by_cities)\n",
    "    data['date'] = dates_sep[d]\n",
    "    moveouts.append(data)\n",
    "#errors = = pd.concat(errors)\n",
    "#errors.to_csv(\"missing_moveout.csv\")\n",
    "data = pd.concat(moveouts)\n",
    "data.to_csv(\"baidu_qianxi_data_moveout\"+year+month+\".csv\", index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b503a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
